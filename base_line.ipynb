{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1ce661",
   "metadata": {},
   "source": [
    "# Построим baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ddb2bc",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd4efe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocess import CustomPreprocessor\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import Lasso,LinearRegression,Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error,r2_score)\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed13e9be",
   "metadata": {},
   "source": [
    "## Считывание данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fac223c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6bba0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1490e3",
   "metadata": {},
   "source": [
    "## Удалим ошибочные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a65fab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train['price'] <= 500_000) & (df_train['price'] >= 100)]\n",
    "df_train = df_train[df_train['odometer'] <= 600_000]\n",
    "\n",
    "df_test = df_test[(df_test['price'] <= 500_000) & (df_test['price'] >= 100)]\n",
    "df_test = df_test[df_test['odometer'] <= 600_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a133ea",
   "metadata": {},
   "source": [
    "## Удаляем из тренировочных данных выбросы и строки с большим количеством пропусков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fba70d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df: pd.DataFrame,train:bool) -> pd.DataFrame:\n",
    "    if train:\n",
    "        # Удаляем строки с большим количеством пропусков\n",
    "        df = df.dropna(thresh=int(df.shape[1]*0.7))\n",
    "        \n",
    "        # Удаление выбросов по IQR для числовых колонок\n",
    "        num_cols = df.select_dtypes(exclude='object').columns.tolist()\n",
    "        for col in num_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            if IQR > 0:\n",
    "                low = Q1 - 1.5*IQR\n",
    "                high = Q3 + 1.5*IQR\n",
    "                df = df[(df[col] >= low) & (df[col] <= high)]\n",
    "    # удалим колонки с большим кол-во уник знач\n",
    "    df.drop(columns=['id', 'url', 'image_url', 'region_url','VIN','county','description','posting_date','model'],inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8107cbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ym/hx_pjxld1rn9q46zklb197b80000gn/T/ipykernel_74609/3925096447.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train_clean[col].fillna(median_value, inplace=True)\n",
      "/var/folders/ym/hx_pjxld1rn9q46zklb197b80000gn/T/ipykernel_74609/3925096447.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test_clean[col].fillna(median_value, inplace=True)\n",
      "/var/folders/ym/hx_pjxld1rn9q46zklb197b80000gn/T/ipykernel_74609/3925096447.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_train_clean[col].fillna(mode_value, inplace=True)\n",
      "/var/folders/ym/hx_pjxld1rn9q46zklb197b80000gn/T/ipykernel_74609/3925096447.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test_clean[col].fillna(mode_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_train_clean = clean_data(df_train,True)\n",
    "df_test_clean = clean_data(df_test,False)\n",
    "\n",
    "\n",
    "num_cols = df_train_clean.select_dtypes(exclude='object').columns.tolist()\n",
    "cat_cols = df_train_clean.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "for col in num_cols:\n",
    "    if df_train_clean[col].isna().all():\n",
    "        df_train_clean[col] = 0\n",
    "        df_test_clean[col] = 0\n",
    "    else:\n",
    "        median_value = df_train_clean[col].median()\n",
    "        df_train_clean[col].fillna(median_value, inplace=True)\n",
    "        df_test_clean[col].fillna(median_value, inplace=True)\n",
    "\n",
    "for col in cat_cols:\n",
    "    if df_train_clean[col].isna().all():\n",
    "        df_train_clean[col] = \"missing\"\n",
    "        df_test_clean[col] = \"missing\"\n",
    "    else:\n",
    "        mode_value = df_train_clean[col].mode()[0]\n",
    "        df_train_clean[col].fillna(mode_value, inplace=True)\n",
    "        df_test_clean[col].fillna(mode_value, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b340c4",
   "metadata": {},
   "source": [
    "## Сравним несколько моделей и выберем наилучшую "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b7076b",
   "metadata": {},
   "source": [
    "### Подготовим данные для обучения,сделав разбиение на train и test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f817ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"price\"\n",
    "\n",
    "X_train = df_train_clean.drop(columns=[\"price\"])\n",
    "X_valid = df_test_clean.drop(columns=[\"price\"])\n",
    "y_train = df_train_clean['price']\n",
    "y_valid = df_test_clean['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff88700",
   "metadata": {},
   "source": [
    "## Для начало рассмотрим стандартную Линейную регрессию "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d7f69",
   "metadata": {},
   "source": [
    "### Для начала закодируем наши категориальные признаки и отмаштабируем их(необходимо для работы с линейными моделями)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11bf642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_features = X_train.select_dtypes(exclude=[\"object\"]).columns\n",
    "cat_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_features),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)\n",
    "])\n",
    "\n",
    "X_train_ready = preprocessor.fit_transform(X_train)\n",
    "X_valid_ready = preprocessor.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd450d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики LinearRegression:\n",
      "MAE:  6899.358328102942\n",
      "RMSE:  12177.702786330286\n",
      "r2:  0.3632694732058199\n"
     ]
    }
   ],
   "source": [
    "model_regres = LinearRegression()\n",
    "model_regres.fit(X_train_ready,y_train)\n",
    "y_pred = model_regres.predict(X_valid_ready)\n",
    "\n",
    "print('Метрики LinearRegression:')\n",
    "print('MAE: ',mean_absolute_error(y_valid,y_pred))\n",
    "print('RMSE: ',np.sqrt(mean_squared_error(y_valid,y_pred)))\n",
    "print('r2: ',r2_score(y_valid,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218b553",
   "metadata": {},
   "source": [
    "## Далее рассмотрим DissisonTree и RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd2d1d8",
   "metadata": {},
   "source": [
    "### Закодируем категориальные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7c69ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding завершён. Закодировано признаков: 12\n"
     ]
    }
   ],
   "source": [
    "X_train_tree = X_train.copy()\n",
    "X_valid_tree = X_valid.copy()\n",
    "\n",
    "cat_features = X_train_tree.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    combined = pd.concat([X_train_tree[col], X_valid_tree[col]], axis=0).astype(str)\n",
    "    le.fit(combined)\n",
    "    \n",
    "    X_train_tree[col] = le.transform(X_train_tree[col].astype(str))\n",
    "    X_valid_tree[col] = le.transform(X_valid_tree[col].astype(str))\n",
    "    \n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"Label Encoding завершён. Закодировано признаков: {len(cat_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d2b2f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280139, 16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tree.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "284b76a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики DecisionTreeRegressor:\n",
      "MAE:  3745.4543003681056\n",
      "RMSE:  9459.61171452306\n",
      "R2:  0.6157874452302391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики RandomForestRegressor:\n",
      "MAE:  4474.295798476559\n",
      "RMSE:  8696.856388309378\n",
      "R2:  0.6752497243436929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree\n",
    "model_tree = DecisionTreeRegressor()\n",
    "model_tree.fit(X_train_tree, y_train)\n",
    "y_pred_tree = model_tree.predict(X_valid_tree)\n",
    "\n",
    "print('Метрики DecisionTreeRegressor:')\n",
    "print('MAE: ', mean_absolute_error(y_valid, y_pred_tree))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_valid, y_pred_tree)))\n",
    "print('R2: ', r2_score(y_valid, y_pred_tree))\n",
    "\n",
    "# RandomForest\n",
    "\n",
    "model_rf = RandomForestRegressor(\n",
    "    n_estimators=100,       # количество деревьев, можно 50 для быстрого теста\n",
    "    max_depth=16,           # ограничение глубины, чтобы избежать переобучения\n",
    "    min_samples_leaf=3,     # минимальное число объектов в листе\n",
    "    max_features='sqrt',    # sqrt(num_features) на каждом разбиении\n",
    "    n_jobs=-1,              # использовать все ядра CPU\n",
    "    random_state=42,\n",
    "    verbose=1               # вывод прогресса\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "model_rf.fit(X_train_tree, y_train)\n",
    "\n",
    "# Предсказание\n",
    "y_pred_rf = model_rf.predict(X_valid_tree)\n",
    "\n",
    "# Метрикчя\n",
    "print('Метрики RandomForestRegressor:')\n",
    "print('MAE: ', mean_absolute_error(y_valid, y_pred_rf))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_valid, y_pred_rf)))\n",
    "print('R2: ', r2_score(y_valid, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9b0d0",
   "metadata": {},
   "source": [
    "### Рассмотрим градиентные бустинги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9fafc",
   "metadata": {},
   "source": [
    "### Для начала обучим catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1be8db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 10082.1150483\ttest: 11050.0612633\tbest: 11050.0612633 (0)\ttotal: 218ms\tremaining: 3m 38s\n",
      "200:\tlearn: 4101.9338186\ttest: 4951.1193076\tbest: 4951.1193076 (200)\ttotal: 1m 5s\tremaining: 4m 19s\n",
      "400:\tlearn: 3839.7178045\ttest: 4681.3089039\tbest: 4681.3089039 (400)\ttotal: 2m 10s\tremaining: 3m 14s\n",
      "600:\tlearn: 3711.8337889\ttest: 4560.1637745\tbest: 4560.1637745 (600)\ttotal: 3m 6s\tremaining: 2m 3s\n",
      "800:\tlearn: 3615.9651405\ttest: 4467.9703966\tbest: 4467.9703966 (800)\ttotal: 3m 52s\tremaining: 57.8s\n",
      "999:\tlearn: 3540.2148667\ttest: 4395.3219799\tbest: 4395.3219799 (999)\ttotal: 4m 40s\tremaining: 0us\n",
      "\n",
      "bestTest = 4395.32198\n",
      "bestIteration = 999\n",
      "\n",
      "Метрики CatBoost:\n",
      "MAE: 4395.321980861931\n",
      "RMSE: 8721.288155474902\n",
      "R2: 0.6734225427894758\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "cat_boost_model = CatBoostRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MAE',\n",
    "    eval_metric='MAE',\n",
    "    random_seed=42,\n",
    "    verbose=200,\n",
    "    early_stopping_rounds=100\n",
    "    )\n",
    "\n",
    "cat_boost_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cat_features=cat_features,\n",
    "    eval_set=(X_valid, y_valid),\n",
    "    use_best_model=True,\n",
    ")\n",
    "\n",
    "y_pred = cat_boost_model.predict(X_valid)\n",
    "\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "print(\"Метрики CatBoost:\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R2: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c81a53",
   "metadata": {},
   "source": [
    "### Обучим ligthgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59c239cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики LightGBM:\n",
      "MAE: 4094.9166\n",
      "RMSE: 8019.7817\n",
      "R2: 0.7238\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Категориальные признаки как category\n",
    "X_train_lgb = X_train.copy()\n",
    "X_valid_lgb = X_valid.copy()\n",
    "cat_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "for col in cat_features:\n",
    "    X_train_lgb[col] = X_train_lgb[col].astype('category')\n",
    "    X_valid_lgb[col] = X_valid_lgb[col].astype('category')\n",
    "\n",
    "lgb_model = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1, \n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    "    early_stopping_rounds=50  \n",
    ")\n",
    "\n",
    "lgb_model.fit(\n",
    "    X_train_lgb,\n",
    "    y_train,\n",
    "    eval_set=[(X_valid_lgb, y_valid)],\n",
    "    eval_metric='mae',\n",
    "    categorical_feature=cat_features \n",
    ")\n",
    "\n",
    "y_pred = lgb_model.predict(X_valid_lgb)\n",
    "\n",
    "mae = mean_absolute_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "print(\"Метрики LightGBM:\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0934f9",
   "metadata": {},
   "source": [
    "### Далее рассмотрим xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c5a4c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики XGBoost:\n",
      "MAE: 4166.3989\n",
      "RMSE: 8184.9142\n",
      "R2: 0.7124\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "X_train_xgb = X_train.copy()\n",
    "X_valid_xgb = X_valid.copy()\n",
    "\n",
    "label_encoders = {}\n",
    "cat_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([X_train[col], X_valid[col]], axis=0)\n",
    "    le.fit(combined)\n",
    "    X_train_xgb[col] = le.transform(X_train_xgb[col])\n",
    "    X_valid_xgb[col] = le.transform(X_valid_xgb[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    verbosity=0,  \n",
    "    early_stopping_rounds=50,\n",
    "    eval_metric='mae'\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train_xgb,\n",
    "    y_train,\n",
    "    eval_set=[(X_valid_xgb, y_valid)],\n",
    "    verbose=False \n",
    ")\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_valid_xgb)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_valid, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_valid, y_pred_xgb))\n",
    "r2_xgb = r2_score(y_valid, y_pred_xgb)\n",
    "\n",
    "print(\"Метрики XGBoost:\")\n",
    "print(f\"MAE: {mae_xgb:.4f}\")\n",
    "print(f\"RMSE: {rmse_xgb:.4f}\")\n",
    "print(f\"R2: {r2_xgb:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
