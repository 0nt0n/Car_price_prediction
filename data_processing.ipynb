{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba948f42",
   "metadata": {},
   "source": [
    "# Подготовим данные для обучении модели,заполним пропуски и создадим новые фичи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721818c",
   "metadata": {},
   "source": [
    "## Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0050b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83120dbe",
   "metadata": {},
   "source": [
    "### Считывание данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2404bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b9e7e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "df_train,df_test = train_test_split(data,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759312b6",
   "metadata": {},
   "source": [
    "## Повторим все манипуляции над данным из файла eda.ipynb,а также поэкспрементируем с новыми фичами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e07c33",
   "metadata": {},
   "source": [
    "## Переведем колонки cylinders и posting_date в другие форматы,для более удобной работы с ними в дальнейшем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3acb1ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование цилиндров\n",
    "df_train['cylinders_num'] =  df_train['cylinders'].str.extract('(\\d+)')\n",
    "df_train['cylinders_num'] = df_train['cylinders_num'].astype(float)\n",
    "\n",
    "# Создание новых числовых признаков\n",
    "df_train['posting_date'] = pd.to_datetime(df_train['posting_date'], errors='coerce', utc=True)\n",
    "df_train['posting_year'] = df_train['posting_date'].dt.year\n",
    "df_train['posting_month'] = df_train['posting_date'].dt.month\n",
    "df_train['posting_day'] = df_train['posting_date'].dt.day\n",
    "df_train['posting_weekday'] = df_train['posting_date'].dt.weekday  \n",
    "df_train['posting_hour'] = df_train['posting_date'].dt.hour\n",
    "\n",
    "df_train.drop(columns=['posting_date','posting_year'],inplace=True)\n",
    "\n",
    "\n",
    "df_test['cylinders_num'] = df_test['cylinders'].str.extract('(\\d+)')\n",
    "df_test['cylinders_num'] = df_test['cylinders_num'].astype(float)\n",
    "\n",
    "\n",
    "df_test['posting_date'] = pd.to_datetime(df_test['posting_date'], errors='coerce', utc=True)\n",
    "df_test['posting_year'] = df_test['posting_date'].dt.year\n",
    "df_test['posting_month'] = df_test['posting_date'].dt.month\n",
    "df_test['posting_day'] = df_test['posting_date'].dt.day\n",
    "df_test['posting_weekday'] = df_test['posting_date'].dt.weekday\n",
    "df_test['posting_hour'] = df_test['posting_date'].dt.hour\n",
    "\n",
    "# Удалим год публикации для того,чтобы \n",
    "df_test.drop(columns=['posting_date','posting_year'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6050951",
   "metadata": {},
   "source": [
    "## Удалим колонки с большим количеством уникальных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "682aa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['id', 'url', 'image_url', 'region_url','VIN'],inplace=True)\n",
    "df_test.drop(columns=['id', 'url', 'image_url', 'region_url','VIN'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22766fd",
   "metadata": {},
   "source": [
    "##  Удалим неинформативные столбцы  из обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "480b56f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_col_to_del(data:pd.DataFrame):\n",
    "    all_k = data.shape[0]\n",
    "    cols_with_null = data.columns[data.isnull().sum() > 0].tolist()\n",
    "    cols_to_drop = []\n",
    "    for col in cols_with_null:\n",
    "        if (data[col].isnull().sum() / all_k) * 100 > 70:\n",
    "            cols_to_drop.append(col)\n",
    "    return cols_to_drop\n",
    "\n",
    "cols_to_drop = find_col_to_del(data=df_train)\n",
    "df_train.drop(columns=cols_to_drop,inplace=True)\n",
    "df_test.drop(columns=cols_to_drop,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f78afc",
   "metadata": {},
   "source": [
    "## Аналогично поступим и со строками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4ce2cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna(thresh=int((df_train.shape[1] / 100) * 70))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92f9b65",
   "metadata": {},
   "source": [
    "## Заполним пропуски"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1c3c3",
   "metadata": {},
   "source": [
    "#### Числовые "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d990daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_num_col_to_fill(data: pd.DataFrame):\n",
    "    num_cols = data.select_dtypes(exclude=['object'])\n",
    "    num_cols_with_null = num_cols.columns[num_cols.isnull().any()].tolist()\n",
    "    return  num_cols_with_null\n",
    "\n",
    "num_cols_to_fil = find_num_col_to_fill(df_train)\n",
    "\n",
    "df_train[num_cols_to_fil] = df_train[num_cols_to_fil].fillna(df_train[num_cols_to_fil].mean())\n",
    "df_test[num_cols_to_fil] = df_test[num_cols_to_fil].fillna(df_train[num_cols_to_fil].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e23e20c",
   "metadata": {},
   "source": [
    "#### Категориальные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "200b4dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cot_col_to_fill(data: pd.DataFrame):\n",
    "    cot_cols = data.select_dtypes(include=['object'])\n",
    "    cot_cols_with_null = [col for col in cot_cols.columns if cot_cols[col].isnull().any() and col != 'description']\n",
    "    return cot_cols_with_null\n",
    "\n",
    "cot_cols_to_fil = find_cot_col_to_fill(df_train)\n",
    "df_train[cot_cols_to_fil] = df_train[cot_cols_to_fil].fillna('unknown')\n",
    "df_train['description'] = df_train['description'].fillna('')\n",
    "df_test[cot_cols_to_fil] = df_test[cot_cols_to_fil].fillna('unknown')\n",
    "df_test['description'] = df_test['description'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51708566",
   "metadata": {},
   "source": [
    "## Очистим от выбросов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4a61df",
   "metadata": {},
   "source": [
    "### Для начала уберем явные выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e81c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train['price'] <= 500_000) & (df_train['price'] >= 100)]\n",
    "df_train = df_train[df_train['odometer'] <= 600_000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02398068",
   "metadata": {},
   "source": [
    "###  Для более объективного и воспроизводимого отбора выбросов я применю метод IQR с кастомными квантилями. Это позволит формально выделить аномалии и гибко настроить границы через коэффициент k, избегая чрезмерного удаления данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82e8ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'year': удалено 5943 выбросов\n",
      "'price': удалено 676 выбросов\n",
      "'odometer': удалено 250 выбросов\n",
      "'long': удалено 18 выбросов\n",
      "'lat': удалено 46 выбросов\n"
     ]
    }
   ],
   "source": [
    "def delete_by_IQR(data: pd.DataFrame, column: str, q_low: float = 0.25, q_high: float = 0.75) -> None:\n",
    "    if column not in data.columns:\n",
    "        print(f\"Колонка '{column}' не найдена в DataFrame\")\n",
    "    \n",
    "    else:\n",
    "        Q1 = data[column].quantile(q_low)\n",
    "        Q3 = data[column].quantile(q_high)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        low_border = Q1 - 1.5 * IQR\n",
    "        high_border = Q3 + 1.5 * IQR\n",
    "\n",
    "        before = len(data)\n",
    "        data.drop(data[(data[column] < low_border) | (data[column] > high_border)].index, inplace=True)\n",
    "        after = len(data)\n",
    "        print(f\"'{column}': удалено {before - after} выбросов\")\n",
    "\n",
    "\n",
    "df_train_clean = df_train.copy()\n",
    "for col in ['year', 'price', 'odometer','long','lat']:\n",
    "    delete_by_IQR(df_train_clean, col, q_low=0.1, q_high=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52f0925",
   "metadata": {},
   "source": [
    "### Посторим на размер датасета после всех удалений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1c0a6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета:  (304255, 23)\n"
     ]
    }
   ],
   "source": [
    "print('Размер датасета: ',df_train_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b75954",
   "metadata": {},
   "source": [
    "## Выделим наиболее встречающиеся значения в колнках region и model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956944b9",
   "metadata": {},
   "source": [
    "### Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3e60e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_counts = df_train_clean['region'].value_counts()\n",
    "top100 = region_counts.head(100)\n",
    "df_train_clean['region_top100'] = df_train_clean['region'].apply(lambda x: x if x in top100.index else 'Other')\n",
    "df_test['region_top100'] = df_test['region'].apply(lambda x: x if x in top100.index else 'Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a777b0",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "272b61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_counts = df_train_clean['model'].value_counts()\n",
    "top250 = model_counts.head(250)\n",
    "df_train_clean['model_top250'] = df_train_clean['model'].apply(lambda x: x if x in top250.index else 'Other')\n",
    "df_test['model_top250'] = df_test['model'].apply(lambda x: x if x in top250.index else 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98ec270a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 304255 entries, 366318 to 121958\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   region           304255 non-null  object \n",
      " 1   price            304255 non-null  int64  \n",
      " 2   year             304255 non-null  float64\n",
      " 3   manufacturer     304255 non-null  object \n",
      " 4   model            304255 non-null  object \n",
      " 5   condition        304255 non-null  object \n",
      " 6   cylinders        304255 non-null  object \n",
      " 7   fuel             304255 non-null  object \n",
      " 8   odometer         304255 non-null  float64\n",
      " 9   title_status     304255 non-null  object \n",
      " 10  transmission     304255 non-null  object \n",
      " 11  drive            304255 non-null  object \n",
      " 12  type             304255 non-null  object \n",
      " 13  paint_color      304255 non-null  object \n",
      " 14  description      304255 non-null  object \n",
      " 15  state            304255 non-null  object \n",
      " 16  lat              304255 non-null  float64\n",
      " 17  long             304255 non-null  float64\n",
      " 18  cylinders_num    304255 non-null  float64\n",
      " 19  posting_month    304255 non-null  float64\n",
      " 20  posting_day      304255 non-null  float64\n",
      " 21  posting_weekday  304255 non-null  float64\n",
      " 22  posting_hour     304255 non-null  float64\n",
      " 23  region_top100    304255 non-null  object \n",
      " 24  model_top250     304255 non-null  object \n",
      "dtypes: float64(9), int64(1), object(15)\n",
      "memory usage: 60.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98e58538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 85376 entries, 100905 to 374513\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   region           85376 non-null  object \n",
      " 1   price            85376 non-null  int64  \n",
      " 2   year             85376 non-null  float64\n",
      " 3   manufacturer     85376 non-null  object \n",
      " 4   model            85376 non-null  object \n",
      " 5   condition        85376 non-null  object \n",
      " 6   cylinders        85376 non-null  object \n",
      " 7   fuel             85376 non-null  object \n",
      " 8   odometer         85376 non-null  float64\n",
      " 9   title_status     85376 non-null  object \n",
      " 10  transmission     85376 non-null  object \n",
      " 11  drive            85376 non-null  object \n",
      " 12  type             85376 non-null  object \n",
      " 13  paint_color      85376 non-null  object \n",
      " 14  description      85376 non-null  object \n",
      " 15  state            85376 non-null  object \n",
      " 16  lat              85376 non-null  float64\n",
      " 17  long             85376 non-null  float64\n",
      " 18  cylinders_num    85376 non-null  float64\n",
      " 19  posting_month    85363 non-null  float64\n",
      " 20  posting_day      85363 non-null  float64\n",
      " 21  posting_weekday  85363 non-null  float64\n",
      " 22  posting_hour     85363 non-null  float64\n",
      " 23  region_top100    85376 non-null  object \n",
      " 24  model_top250     85376 non-null  object \n",
      "dtypes: float64(9), int64(1), object(15)\n",
      "memory usage: 16.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1932f476",
   "metadata": {},
   "source": [
    "## Добавим новые признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb14f516",
   "metadata": {},
   "source": [
    "### Переписать "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe3ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(data,num_columns = []):\n",
    "    \"\"\"Функция для создания новых фич\"\"\"\n",
    "\n",
    "    ### Для начала логарифмировуем  \n",
    "    for col in num_columns:\n",
    "        if col not in ['price','lat','long']:\n",
    "            data[f'log_{col}'] = np.log1p(data[col])\n",
    "    \n",
    "    ### Создадим новые признаки\n",
    "    data['car_age'] = 2021 - data['year']\n",
    "    data['mileage_per_year'] = data['odometer'] / (data['car_age'] + 1)\n",
    "\n",
    "    ### Сделаем бины по координатам\n",
    "    data['region_lat_bin'] = pd.cut(data['lat'], bins=10, labels=False)\n",
    "    data['region_long_bin'] = pd.cut(data['long'], bins=10, labels=False)\n",
    "    data['lat_long_cluster'] = (data['region_lat_bin'] * 10 + data['region_long_bin']).astype(int)\n",
    "\n",
    "    ### Сделаем признаки на основе описания (можно добавить ещё) \n",
    "    data['len_description'] = data['description'].str.len()\n",
    "    data['word_count'] = data['description'].str.split().apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d7655c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "num_cols = df_train_clean.select_dtypes(exclude='object').columns\n",
    "create_features(df_train_clean,num_cols)\n",
    "create_features(df_test,num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2c245756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 304255 entries, 366318 to 121958\n",
      "Data columns (total 42 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   region               304255 non-null  object \n",
      " 1   price                304255 non-null  int64  \n",
      " 2   year                 304255 non-null  float64\n",
      " 3   manufacturer         304255 non-null  object \n",
      " 4   model                304255 non-null  object \n",
      " 5   condition            304255 non-null  object \n",
      " 6   cylinders            304255 non-null  object \n",
      " 7   fuel                 304255 non-null  object \n",
      " 8   odometer             304255 non-null  float64\n",
      " 9   title_status         304255 non-null  object \n",
      " 10  transmission         304255 non-null  object \n",
      " 11  drive                304255 non-null  object \n",
      " 12  type                 304255 non-null  object \n",
      " 13  paint_color          304255 non-null  object \n",
      " 14  description          304255 non-null  object \n",
      " 15  state                304255 non-null  object \n",
      " 16  lat                  304255 non-null  float64\n",
      " 17  long                 304255 non-null  float64\n",
      " 18  cylinders_num        304255 non-null  float64\n",
      " 19  posting_month        304255 non-null  float64\n",
      " 20  posting_day          304255 non-null  float64\n",
      " 21  posting_weekday      304255 non-null  float64\n",
      " 22  posting_hour         304255 non-null  float64\n",
      " 23  region_top100        304255 non-null  object \n",
      " 24  model_top250         304255 non-null  object \n",
      " 25  log_price            304255 non-null  float64\n",
      " 26  log_year             304255 non-null  float64\n",
      " 27  log_odometer         304255 non-null  float64\n",
      " 28  log_lat              304255 non-null  float64\n",
      " 29  log_long             0 non-null       float64\n",
      " 30  log_cylinders_num    304255 non-null  float64\n",
      " 31  log_posting_month    304255 non-null  float64\n",
      " 32  log_posting_day      304255 non-null  float64\n",
      " 33  log_posting_weekday  304255 non-null  float64\n",
      " 34  log_posting_hour     304255 non-null  float64\n",
      " 35  car_age              304255 non-null  float64\n",
      " 36  mileage_per_year     304255 non-null  float64\n",
      " 37  region_lat_bin       304255 non-null  int64  \n",
      " 38  region_long_bin      304255 non-null  int64  \n",
      " 39  lat_long_cluster     304255 non-null  int64  \n",
      " 40  len_description      304255 non-null  int64  \n",
      " 41  word_count           304255 non-null  int64  \n",
      "dtypes: float64(21), int64(6), object(15)\n",
      "memory usage: 99.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c02d260",
   "metadata": {},
   "source": [
    "## Также более детально поработаем с текстом,а именно с описанием"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6dec90",
   "metadata": {},
   "source": [
    "### Применим TF-IDF для кодировки категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c0c3d72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "525dc611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Создаём TF-IDF и задаём параметры\n",
    "# tfidf = TfidfVectorizer(\n",
    "#     max_features=2000,    # оставляем только топ слов\n",
    "#     stop_words='english', # английские стоп-слова\n",
    "#     ngram_range=(1,2)     # униграммы и биграммы\n",
    "# )\n",
    "\n",
    "# # 2. Учим TF-IDF на train\n",
    "# X_train_desc = tfidf.fit_transform(df_train['description'].fillna(''))\n",
    "\n",
    "# # 3. Применяем тот же TF-IDF к valid/test\n",
    "# X_valid_desc = tfidf.transform(df_test['description'].fillna(''))\n",
    "\n",
    "# # 4. Объединяем с числовыми признаками\n",
    "# X_train_final = hstack([df_train.drop(columns=['description']), X_train_desc])\n",
    "# X_valid_final = hstack([df_test.drop(columns=['description']), X_valid_desc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0caeb",
   "metadata": {},
   "source": [
    "# Проверка "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a68937",
   "metadata": {},
   "source": [
    "### Сравнивая метрики моделей, обученных на baseline, можно оценить эффективность внесённых изменений в признаки и модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a806d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
